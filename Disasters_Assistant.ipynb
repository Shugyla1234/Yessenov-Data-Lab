{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shugyla1234/Yessenov-Data-Lab/blob/main/Disasters_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P8KrERv27_1"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "openai.key"
      ],
      "metadata": {
        "id": "la5iZOll29sz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import PIL\n",
        "import base64\n",
        "import gradio as gr\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "_vsFOQuH6v7R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I hid the API key due to privacy and security\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "OPENAI_API_KEY = \"YOUR REAL KEY\"\n",
        "OPENAI_ENDPOINT\n",
        "OPENAI_DEPLOYMENT\n",
        "OPENAI_API_VERSION\n",
        "OPENAI_DEPLOYMENT_EMBEDDING\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=OPENAI_ENDPOINT,\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    api_version=OPENAI_API_VERSION,\n",
        ")"
      ],
      "metadata": {
        "id": "kP9bP_dj6xpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gradio as gr\n",
        "\n",
        "def survival_assistant(location, threat, family, no_net):\n",
        "    prompt = f\"\"\"\n",
        "Civilian Survival Request\n",
        "\n",
        "Crisis Info:\n",
        "- Location: {location}\n",
        "- Threat: {threat}\n",
        "- Family: {family}\n",
        "- Internet/electricity: {\"No\" if no_net else \"Yes\"}\n",
        "\n",
        "Give calm, short instructions:\n",
        "- What to do\n",
        "- What to pack\n",
        "- How to stay safe\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=OPENAI_DEPLOYMENT,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=800\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "\n",
        "disaster_types = [\n",
        "    \"Airstrike\",\n",
        "    \"Evacuation\",\n",
        "    \"Occupation\",\n",
        "    \"Blackout\",\n",
        "    \"Earthquake\",\n",
        "    \"Tsunami\",\n",
        "    \"Nuclear Explosion\",\n",
        "    \"Flood\",\n",
        "    \"Wildfire\",\n",
        "    \"Chemical Leak\",\n",
        "    \"Missile Strike\",\n",
        "    \"Civil Unrest\"\n",
        "]\n",
        "\n",
        "gr.Interface(\n",
        "    fn=survival_assistant,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"üìç Location\", placeholder=\"e.g. Gaza\"),\n",
        "        gr.Dropdown(disaster_types, label=\"üß® Threat\"),\n",
        "        gr.Textbox(label=\"üë®‚Äçüë©‚Äçüëß Family\", placeholder=\"e.g. 2 kids, grandma\"),\n",
        "        gr.Checkbox(label=\"üö´ No Internet\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"üõ°Ô∏è Survival Plan\", lines=12),\n",
        "    title=\"üõ°Ô∏è AI Civil Survival Assistant\",\n",
        "    description=\"Get a survival plan tailored to your situation ‚Äî including natural and man-made disasters.\"\n",
        ").launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "smcMsJAs60OB",
        "outputId": "6cd7fddf-8969-4392-95c4-796a5ca6a6bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b585b9b20365a87cba.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b585b9b20365a87cba.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Offline Disaster Network & Locator App (Works with coordinates)"
      ],
      "metadata": {
        "id": "YVtTLShd66nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import math\n",
        "OPENAI_DEPLOYMENT\n",
        "shelters = [\n",
        "    {\"name\": \"Central Metro Bunker\", \"lat\": 40.7128, \"lon\": -74.0060, \"type\": \"shelter\"},\n",
        "    {\"name\": \"Red Cross Tent\", \"lat\": 40.7132, \"lon\": -74.0005, \"type\": \"medical\"},\n",
        "    {\"name\": \"UN Food Station\", \"lat\": 40.7140, \"lon\": -74.0021, \"type\": \"food\"},\n",
        "]\n",
        "def haversine(lat1, lon1, lat2, lon2):\n",
        "    R = 6371\n",
        "    d_lat, d_lon = math.radians(lat2 - lat1), math.radians(lon2 - lon1)\n",
        "    a = math.sin(d_lat/2)**2 + math.cos(math.radians(lat1)) * math.cos(math.radians(lat2)) * math.sin(d_lon/2)**2\n",
        "    return R * (2 * math.atan2(math.sqrt(a), math.sqrt(1 - a)))\n",
        "def find_nearest(lat, lon, need):\n",
        "    filtered = [s for s in shelters if need.lower() in s[\"type\"]]\n",
        "    sorted_places = sorted(filtered, key=lambda x: haversine(lat, lon, x[\"lat\"], x[\"lon\"]))\n",
        "    return sorted_places[0] if sorted_places else None\n",
        "def disaster_locator(lat, lon, need):\n",
        "    nearest = find_nearest(lat, lon, need)\n",
        "    if not nearest:\n",
        "        return \"No resources nearby. Try a different need.\", None\n",
        "\n",
        "    shelter_info = f\"{nearest['name']} at ({nearest['lat']:.4f}, {nearest['lon']:.4f})\"\n",
        "\n",
        "    gpt_prompt = f\"\"\"\n",
        "You're an emergency assistant helping a disaster victim.\n",
        "\n",
        "They're located at ({lat}, {lon}), and they need: {need}.\n",
        "\n",
        "You found this location: {shelter_info}.\n",
        "\n",
        "Give calm, clear directions to reach this place and what to expect there.\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=OPENAI_DEPLOYMENT,\n",
        "        messages=[{\"role\": \"user\", \"content\": gpt_prompt}]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content, shelter_info\n",
        "\n",
        "\n",
        "gr.Interface(\n",
        "    fn=disaster_locator,\n",
        "    inputs=[\n",
        "        gr.Number(label=\"üìç Latitude\"),\n",
        "        gr.Number(label=\"üìç Longitude\"),\n",
        "        gr.Dropdown([\"shelter\", \"medical\", \"food\"], label=\"What do you need?\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"üì¢ Instructions\"),\n",
        "        gr.Textbox(label=\"üìå Nearest Location\")\n",
        "    ],\n",
        "    title=\"üÜò Disaster Survival Locator\"\n",
        ").launch(debug=True)\n"
      ],
      "metadata": {
        "id": "uRmFZULC7G3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Offline Disaster Network & Locator App (Version 2)"
      ],
      "metadata": {
        "id": "pj_2mXuX7M-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I hid the API key due to privacy and security\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "OPENAI_API_KEY = \"YOUR REAL KEY\"\n",
        "OPENAI_ENDPOINT\n",
        "OPENAI_DEPLOYMENT\n",
        "OPENAI_API_VERSION\n",
        "OPENAI_DEPLOYMENT_EMBEDDING\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=OPENAI_ENDPOINT,\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    api_version=OPENAI_API_VERSION,\n",
        ")\n",
        "\n",
        "shelters = [\n",
        "    {\"name\": \"AlmaU Underground Shelter\", \"location\": \"Almaty, near AlmaU\", \"type\": \"shelter\"},\n",
        "    {\"name\": \"KazRed Emergency Tent\", \"location\": \"Almaty, Dostyk Avenue\", \"type\": \"medical\"},\n",
        "    {\"name\": \"UN Food Station\", \"location\": \"Almaty, Sayran Bus Terminal\", \"type\": \"food\"},\n",
        "    {\"name\": \"NYC Central Metro Bunker\", \"location\": \"New York\", \"type\": \"shelter\"},\n",
        "]\n",
        "\n",
        "def disaster_locator(location_text, need):\n",
        "    shelter_list = [s for s in shelters if need.lower() in s[\"type\"]]\n",
        "    if not shelter_list:\n",
        "        return \"No resources found for this need.\", \"\"\n",
        "    gpt_prompt = f\"\"\"\n",
        "You're a calm and clear emergency assistant helping a disaster victim.\n",
        "\n",
        "They are currently at: {location_text}\n",
        "They are looking for: {need}\n",
        "\n",
        "These are possible support centers:\n",
        "\n",
        "{chr(10).join([f\"- {s['name']} at {s['location']}\" for s in shelter_list])}\n",
        "\n",
        "Based on their location, give a brief explanation of which shelter is most likely closest,\n",
        "and how to reach it. Offer simple survival guidance.\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=OPENAI_DEPLOYMENT,\n",
        "        messages=[{\"role\": \"user\", \"content\": gpt_prompt}],\n",
        "        temperature=0.5,\n",
        "        max_tokens=600\n",
        "    )\n",
        "    instructions = response.choices[0].message.content.strip()\n",
        "    top_shelter = shelter_list[0][\"name\"] + \" at \" + shelter_list[0][\"location\"]\n",
        "\n",
        "    return instructions, top_shelter\n",
        "gr.Interface(\n",
        "    fn=disaster_locator,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"üìç Where are you right now?\", placeholder=\"e.g. near Al-Quds Hospital, Gaza\"),\n",
        "        gr.Dropdown([\"shelter\", \"medical\", \"food\"], label=\"üö® What do you need?\")\n",
        "    ],\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"üì¢ Emergency Instructions\", lines=10),\n",
        "        gr.Textbox(label=\"üìå Nearest Known Shelter\")\n",
        "    ],\n",
        "    title=\"üÜò AI Disaster Assistant (Location-Aware)\",\n",
        "    description=\"Type your location and need. The assistant will suggest where to go and how.\"\n",
        ").launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "Acj5tpbO7PZH",
        "outputId": "d093d4af-9ce1-4dd8-9f77-d85bf254822f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://9af4c29d9d20134a42.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9af4c29d9d20134a42.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9af4c29d9d20134a42.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#AI Lost Contact Assistant\n",
        "## Helping people reconnect during disasters or war when traditional communication fails"
      ],
      "metadata": {
        "id": "o1K6ZJVJ73-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "def lost_contact_assistant(last_seen, destination, contact_method, emotional_msg):\n",
        "    prompt = f\"\"\"\n",
        "You are an emergency contact assistant. Someone is trying to reconnect with a missing person during a disaster.\n",
        "\n",
        "Here is the situation:\n",
        "- Last seen location: {last_seen}\n",
        "- They were heading towards: {destination}\n",
        "- Communication available: {contact_method}\n",
        "- Add emotional message to comfort the user: {emotional_msg}\n",
        "\n",
        "Your tasks:\n",
        "- Suggest where the person might be now, based on geography and crisis logic\n",
        "- Recommend how to try to contact them (e.g., radio, relay stations, messages)\n",
        "- Give clear, calm guidance\n",
        "- End with a short emotional comfort message\n",
        "\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=OPENAI_DEPLOYMENT,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=800\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "gr.Interface(\n",
        "    fn=lost_contact_assistant,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"üìç Last Seen Location\", placeholder=\"e.g. North Gaza, water tower\"),\n",
        "        gr.Textbox(label=\"‚û°Ô∏è Direction They Were Going\", placeholder=\"e.g. South toward Khan Younis\"),\n",
        "        gr.Radio([\"Internet\", \"Radio\", \"None\"], label=\"üì° Communication Available\"),\n",
        "        gr.Textbox(label=\"üí¨ Emotional Message\", placeholder=\"e.g. I hope you're safe, please come back...\"),\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"üì¢ Contact Plan and Support Message\", lines=12),\n",
        "    title=\"üõ∞Ô∏è AI Lost Contact Assistant\",\n",
        "    description=\"Helps reconnect with people lost during war, evacuation, or disasters using GPT survival logic.\"\n",
        ").launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "id": "gXuOJS0p77oM",
        "outputId": "95a65fa2-a632-4b36-bd24-46137c574f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://90a14f16b882a41332.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://90a14f16b882a41332.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://90a14f16b882a41332.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Voice Input + Text-to-Speech\n",
        "## Let the user speak the emergency situation instead of typing it+ Read the instructions aloud for kids or elderly who can't read"
      ],
      "metadata": {
        "id": "PQ82onBQ9PRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyttsx3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czdDnSgE9Y-i",
        "outputId": "b161be18-93f5-4895-c682-adb539c01977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyttsx3 in /usr/local/lib/python3.11/dist-packages (2.98)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install -y espeak"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzayKXpk9baJ",
        "outputId": "7dd50b81-e7a5-4098-866f-d7c867eb574b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "espeak is already the newest version (1.48.15+dfsg-3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SpeechRecognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-rw-HcA9b_Y",
        "outputId": "d463cab5-0060-44d3-88e0-306423a086a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.11/dist-packages (3.14.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from SpeechRecognition) (4.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from openai import AzureOpenAI\n",
        "import tempfile\n",
        "import os\n",
        "import subprocess\n",
        "import speech_recognition as sr\n",
        "import pyttsx3\n",
        "\n",
        "# I hid the API key due to privacy and security\n",
        "from openai import AzureOpenAI\n",
        "\n",
        "OPENAI_API_KEY = \"YOUR REAL KEY\"\n",
        "OPENAI_ENDPOINT\n",
        "OPENAI_DEPLOYMENT\n",
        "OPENAI_API_VERSION\n",
        "OPENAI_DEPLOYMENT_EMBEDDING\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=OPENAI_ENDPOINT,\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    api_version=OPENAI_API_VERSION,\n",
        ")\n",
        "\n",
        "\n",
        "def convert_to_wav(input_path):\n",
        "    if input_path is None or not os.path.exists(input_path):\n",
        "        raise ValueError(\"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω –∏–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.\")\n",
        "    output_path = input_path + \".wav\"\n",
        "    subprocess.run([\"ffmpeg\", \"-i\", input_path, output_path, \"-y\", \"-loglevel\", \"quiet\"])\n",
        "    if not os.path.exists(output_path):\n",
        "        raise ValueError(\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ.\")\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def voice_input_survival(audio_path):\n",
        "    print(f\"–ü–æ–ª—É—á–µ–Ω audio_path: {audio_path}\")\n",
        "    wav_path = convert_to_wav(audio_path)\n",
        "\n",
        "\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(wav_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "        try:\n",
        "            scenario = recognizer.recognize_google(audio)\n",
        "        except sr.UnknownValueError:\n",
        "            return \"ü§∑ –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.\", \"\", None\n",
        "\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a survival expert. Write a short, calm 3‚Äì5 step guide for this situation:\n",
        "Scenario: {scenario}\n",
        "Steps should be clear and simple.\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=OPENAI_DEPLOYMENT,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=400\n",
        "    )\n",
        "    instructions = response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "    engine = pyttsx3.init()\n",
        "    temp_audio_path = tempfile.mktemp(suffix=\".mp3\")\n",
        "    engine.save_to_file(instructions, temp_audio_path)\n",
        "    engine.runAndWait()\n",
        "\n",
        "    return scenario, instructions, temp_audio_path\n",
        "\n",
        "gr.Interface(\n",
        "    fn=voice_input_survival,\n",
        "    inputs=gr.Audio(label=\"üé§ Speak Your Disaster Scenario\", type=\"filepath\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"üìù Recognized Scenario\"),\n",
        "        gr.Textbox(label=\"üìã Survival Instructions\", lines=10),\n",
        "        gr.Audio(label=\"üîä Audio Guide\", type=\"filepath\")\n",
        "    ],\n",
        "    title=\"üó£Ô∏è Voice-Based Disaster Survival Guide\",\n",
        "    description=\"Speak your emergency situation and get clear voice instructions.\"\n",
        ").launch(debug=True)\n",
        "\n",
        "\n",
        "\n",
        "def voice_input_survival(audio_path):\n",
        "    print(f\"–ü–æ–ª—É—á–µ–Ω audio_path: {audio_path}\")\n",
        "    wav_path = convert_to_wav(audio_path)\n",
        "\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(wav_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "        try:\n",
        "            scenario = recognizer.recognize_google(audio)\n",
        "            print(f\"üéôÔ∏è –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {scenario}\")\n",
        "        except sr.UnknownValueError:\n",
        "            return \"ü§∑ –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.\", \"\", None\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a survival expert. Write a short, calm 3‚Äì5 step guide for this situation:\n",
        "Scenario: {scenario}\n",
        "Steps should be clear and simple.\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=OPENAI_DEPLOYMENT,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=400\n",
        "    )\n",
        "    instructions = response.choices[0].message.content.strip()\n",
        "    print(f\"üìã –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏: {instructions}\")\n",
        "\n",
        "\n",
        "    engine = pyttsx3.init()\n",
        "    temp_wav_path = tempfile.mktemp(suffix=\".wav\")\n",
        "    engine.save_to_file(instructions, temp_wav_path)\n",
        "    engine.runAndWait()\n",
        "    print(f\"‚úÖ Audio saved to WAV: {temp_wav_path}\")\n",
        "\n",
        "\n",
        "    temp_mp3_path = temp_wav_path.replace(\".wav\", \".mp3\")\n",
        "    subprocess.run([\"ffmpeg\", \"-i\", temp_wav_path, temp_mp3_path, \"-y\", \"-loglevel\", \"quiet\"])\n",
        "    print(f\"‚úÖ Converted to MP3: {temp_mp3_path}\")\n",
        "\n",
        "    return scenario, instructions, temp_mp3_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "onp5lym2MZBV",
        "outputId": "0e754c30-c0e0-4433-be19-e35459b85e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://bc4cea8efc78acc902.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bc4cea8efc78acc902.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–æ–ª—É—á–µ–Ω audio_path: /tmp/gradio/a6368edeac8346ff593dd24eb553d24dc6307855bdc121cc628fd3b788fb4ac2/ttsMP3.com_VoiceText_2025-7-4_13-12-29.mp3\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://bc4cea8efc78acc902.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import gradio as gr\n",
        "from openai import AzureOpenAI\n",
        "import tempfile\n",
        "import os\n",
        "import subprocess\n",
        "import speech_recognition as sr\n",
        "import pyttsx3\n",
        "\n",
        "\n",
        "OPENAI_API_KEY = \"YOUR REAL KEY\"\n",
        "OPENAI_ENDPOINT\n",
        "OPENAI_DEPLOYMENT\n",
        "OPENAI_API_VERSION\n",
        "OPENAI_DEPLOYMENT_EMBEDDING\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint=OPENAI_ENDPOINT,\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    api_version=OPENAI_API_VERSION,\n",
        ")\n",
        "\n",
        "\n",
        "def convert_to_wav(input_path):\n",
        "    output_path = input_path + \".wav\"\n",
        "    subprocess.run([\"ffmpeg\", \"-i\", input_path, output_path, \"-y\", \"-loglevel\", \"quiet\"])\n",
        "    return output_path\n",
        "\n",
        "def voice_input_survival(audio_path):\n",
        "    wav_path = convert_to_wav(audio_path)\n",
        "\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(wav_path) as source:\n",
        "        audio = recognizer.record(source)\n",
        "        scenario = recognizer.recognize_google(audio)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a survival expert. Write a short, calm 3‚Äì5 step guide for this situation:\n",
        "Scenario: {scenario}\n",
        "Steps should be clear and simple.\n",
        "\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=OPENAI_DEPLOYMENT,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.7,\n",
        "        max_tokens=400\n",
        "    )\n",
        "    instructions = response.choices[0].message.content\n",
        "\n",
        "    temp_audio = tempfile.NamedTemporaryFile(suffix=\".mp3\", delete=False)\n",
        "    engine = pyttsx3.init()\n",
        "    engine.save_to_file(instructions, temp_audio.name)\n",
        "    engine.runAndWait()\n",
        "\n",
        "    return scenario, instructions, temp_audio.name\n",
        "\n",
        "gr.Interface(\n",
        "    fn=voice_input_survival,\n",
        "    inputs=gr.Audio(sources=\"microphone\", label=\"üé§ Speak Your Disaster Scenario\", streaming=True),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"üìù Recognized Scenario\"),\n",
        "        gr.Textbox(label=\"üìã Survival Instructions\", lines=10),\n",
        "        gr.Audio(label=\"üîä Audio Guide\")\n",
        "    ],\n",
        "    title=\"üó£Ô∏è Voice-Based Disaster Survival Guide\",\n",
        "    description=\"Speak your emergency situation and get clear voice instructions.\"\n",
        ").launch(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        },
        "id": "RVSuTjkW9hMT",
        "outputId": "d75d6bb8-cd12-4c51-b2e2-aaac0476dcb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:766: UserWarning: Streaming components are only supported in live interfaces.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://a62ffeb133e701e66f.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a62ffeb133e701e66f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7861 <> https://a62ffeb133e701e66f.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5JnYY-u1TSEO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}